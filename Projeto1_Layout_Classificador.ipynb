{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Felipe Catapano\n",
    "\n",
    "Nome: Rafael Eli Katri\n",
    "\n",
    "Nome: Natan Kron Goldenberg Lewi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Usuario\\Desktop\\Insper\\Segundo Semestre\\Ciência dos Dados\\CD21-2-main\\NBayes-Tweet-Classifier\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "filename = 'Minecraft.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train = pd.read_excel(filename)\n",
    "train = train.loc[:,['Treinamento','Rafa','Classificação']]\n",
    "train.columns = ['Tweet','Integrante','Classificação']\n",
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Integrante</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partiu jogar ❤️\\n\\n#minecraft</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@guilovespink ah sim, eu tenho meu projetinho ...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agr vai ser tudo na base do mais profundo ódio...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vinimonteuro @azulgreatcat minecraft comes al...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vou fazer casinha no minecraft\\n\\nalguem tem x...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Integrante  Classificação\n",
       "0                      partiu jogar ❤️\\n\\n#minecraft       Rafa              2\n",
       "1  @guilovespink ah sim, eu tenho meu projetinho ...       Rafa              3\n",
       "2  agr vai ser tudo na base do mais profundo ódio...       Rafa              0\n",
       "3  @vinimonteuro @azulgreatcat minecraft comes al...       Rafa              0\n",
       "4  vou fazer casinha no minecraft\\n\\nalguem tem x...       Rafa              2"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test = test.loc[:,['Teste','Unnamed: 14','Classificador']]\n",
    "test.columns = ['Tweet','Integrante','Classificação']\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Integrante</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agr.  ta indo. minecraft. se. ela. apaga meu m...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cups_gu pra mim o melhor jogo é minecraft, ma...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@junnotfound_ @alguem_aitlgd @mineperfeito ele...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu passei o dia inteiro jogando minecraft jss ...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lol ache uma partida rapido se nn vou ficar a ...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Integrante  Classificação\n",
       "0  agr.  ta indo. minecraft. se. ela. apaga meu m...      Natan              1\n",
       "1  @cups_gu pra mim o melhor jogo é minecraft, ma...      Natan              1\n",
       "2  @junnotfound_ @alguem_aitlgd @mineperfeito ele...      Natan              2\n",
       "3  eu passei o dia inteiro jogando minecraft jss ...      Natan              3\n",
       "4  lol ache uma partida rapido se nn vou ficar a ...      Natan              1"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O produto escolhido foi o videojogo Minecraft, desenvolvido pela empresa Mojang. Escolhemos esse jogo devido ao alto volume de tweets que ele movimenta, graças à forte comunidade que o sustenta.\n",
    "Classificamos os tweets entre 4 graus de classificação, em ordem crescente de relevância:\n",
    "- O primeiro (0) seria de tweets que não são coesos e não possuem relevância ao jogo.\n",
    "- O próximo (1) é composto de tweets que não tem foco no Minecraft, mas o jogo tem certa relevância no texto.\n",
    "- O nível 2 é formado por tweets cujo principal tema é Minecraft, mas não entra em termos técnicos do jogo.\n",
    "- Por fim, o nível 3 é formado de tweets centrados em Minecraft, os quais descrevem aspectos técnicos do jogo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Transforma o texto dos tweets em minúsculo para padronizar palavras idênticas que tenham variação nesse quesito:\n",
    "\n",
    "train[\"Tweet\"].str.lower()\n",
    "test[\"Tweet\"].str.lower()\n",
    "\n",
    "# Separa o texto de cada tweet em palavras:\n",
    "\n",
    "lista = list()\n",
    "for el in train[\"Tweet\"]:\n",
    "    # Tira espaços extras\n",
    "    limpando = \" \".join(el.split())\n",
    "    words = limpando.split()\n",
    "    lista.append(words)\n",
    "train[\"Palavras\"] = lista\n",
    "\n",
    "lista = list()\n",
    "for el in test[\"Tweet\"]:\n",
    "    # Tira espaços extras\n",
    "    limpando = \" \".join(el.split())\n",
    "    words = limpando.split()\n",
    "    lista.append(words)\n",
    "test[\"Palavras\"] = lista\n",
    "\n",
    "# Filtra caracteres especiais e stopwords:\n",
    "\n",
    "charstop = ['?','!','.',',','(',')','[',']','{','}','<','>','-',':','|','┃']\n",
    "\n",
    "palavrastop = ['a','o','as','os','umas','uns','eu','voce','pra','ele','ela','elas','eles','agnt','um','do','de','da','das','dos','e','na','no','em','meu','para','pela','pelo','que','q']\n",
    "\n",
    "lista = list()\n",
    "for el in train['Palavras']:\n",
    "    liste = []\n",
    "    for x in el:\n",
    "        if any(char in charstop for char in x):\n",
    "            for stp in charstop:\n",
    "                x = x.replace(stp,\"\")\n",
    "        if x != \"\" and (x not in palavrastop and x not in stopwords.words('portuguese')):\n",
    "            liste.append(x)\n",
    "    lista.append(liste)\n",
    "train['Filtrado'] = lista\n",
    "\n",
    "lista = list()\n",
    "for el in test['Palavras']:\n",
    "    liste = []\n",
    "    for x in el:\n",
    "        if any(char in charstop for char in x):\n",
    "            for stp in charstop:\n",
    "                x = x.replace(stp,\"\")\n",
    "        if x != \"\" and (x not in palavrastop and x not in stopwords.words('portuguese')):\n",
    "            liste.append(x)\n",
    "    lista.append(liste)\n",
    "test['Filtrado'] = lista\n",
    "\n",
    "train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Integrante</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partiu jogar ❤️\\n\\n#minecraft</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "      <td>[partiu, jogar, ❤️, #minecraft]</td>\n",
       "      <td>[partiu, jogar, ❤️, #minecraft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@guilovespink ah sim, eu tenho meu projetinho ...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>3</td>\n",
       "      <td>[@guilovespink, ah, sim,, eu, tenho, meu, proj...</td>\n",
       "      <td>[@guilovespink, ah, sim, projetinho, modpack, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agr vai ser tudo na base do mais profundo ódio...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "      <td>[agr, vai, ser, tudo, na, base, do, mais, prof...</td>\n",
       "      <td>[agr, vai, ser, tudo, base, profundo, ódio, nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vinimonteuro @azulgreatcat minecraft comes al...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "      <td>[@vinimonteuro, @azulgreatcat, minecraft, come...</td>\n",
       "      <td>[@vinimonteuro, @azulgreatcat, minecraft, come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vou fazer casinha no minecraft\\n\\nalguem tem x...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "      <td>[vou, fazer, casinha, no, minecraft, alguem, t...</td>\n",
       "      <td>[vou, fazer, casinha, minecraft, alguem, xbox,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>essa é pra voce sonysta que gosta de vendinhas...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>3</td>\n",
       "      <td>[essa, é, pra, voce, sonysta, que, gosta, de, ...</td>\n",
       "      <td>[sonysta, gosta, vendinhas, saiba, jogo, conso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>q odio eu tive insônia hj… por culpa de minecraft</td>\n",
       "      <td>Natan</td>\n",
       "      <td>0</td>\n",
       "      <td>[q, odio, eu, tive, insônia, hj…, por, culpa, ...</td>\n",
       "      <td>[odio, insônia, hj…, culpa, minecraft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>@edit_by_fresh bom dia p quem foi hackeado no ...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>2</td>\n",
       "      <td>[@edit_by_fresh, bom, dia, p, quem, foi, hacke...</td>\n",
       "      <td>[@edit_by_fresh, bom, dia, p, hackeado, minecr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>“só disse isso pra tu olhar o twitter dnv” dis...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>0</td>\n",
       "      <td>[“só, disse, isso, pra, tu, olhar, o, twitter,...</td>\n",
       "      <td>[“só, disse, olhar, twitter, dnv”, disse, feli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>[9/6, 04:03] pedrinho: para de falar em pica m...</td>\n",
       "      <td>Natan</td>\n",
       "      <td>0</td>\n",
       "      <td>[[9/6,, 04:03], pedrinho:, para, de, falar, em...</td>\n",
       "      <td>[9/6, 0403, pedrinho, falar, pica, mano, to, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet Integrante  \\\n",
       "0                        partiu jogar ❤️\\n\\n#minecraft       Rafa   \n",
       "1    @guilovespink ah sim, eu tenho meu projetinho ...       Rafa   \n",
       "2    agr vai ser tudo na base do mais profundo ódio...       Rafa   \n",
       "3    @vinimonteuro @azulgreatcat minecraft comes al...       Rafa   \n",
       "4    vou fazer casinha no minecraft\\n\\nalguem tem x...       Rafa   \n",
       "..                                                 ...        ...   \n",
       "445  essa é pra voce sonysta que gosta de vendinhas...      Natan   \n",
       "446  q odio eu tive insônia hj… por culpa de minecraft      Natan   \n",
       "447  @edit_by_fresh bom dia p quem foi hackeado no ...      Natan   \n",
       "448  “só disse isso pra tu olhar o twitter dnv” dis...      Natan   \n",
       "449  [9/6, 04:03] pedrinho: para de falar em pica m...      Natan   \n",
       "\n",
       "     Classificação                                           Palavras  \\\n",
       "0                2                    [partiu, jogar, ❤️, #minecraft]   \n",
       "1                3  [@guilovespink, ah, sim,, eu, tenho, meu, proj...   \n",
       "2                0  [agr, vai, ser, tudo, na, base, do, mais, prof...   \n",
       "3                0  [@vinimonteuro, @azulgreatcat, minecraft, come...   \n",
       "4                2  [vou, fazer, casinha, no, minecraft, alguem, t...   \n",
       "..             ...                                                ...   \n",
       "445              3  [essa, é, pra, voce, sonysta, que, gosta, de, ...   \n",
       "446              0  [q, odio, eu, tive, insônia, hj…, por, culpa, ...   \n",
       "447              2  [@edit_by_fresh, bom, dia, p, quem, foi, hacke...   \n",
       "448              0  [“só, disse, isso, pra, tu, olhar, o, twitter,...   \n",
       "449              0  [[9/6,, 04:03], pedrinho:, para, de, falar, em...   \n",
       "\n",
       "                                              Filtrado  \n",
       "0                      [partiu, jogar, ❤️, #minecraft]  \n",
       "1    [@guilovespink, ah, sim, projetinho, modpack, ...  \n",
       "2    [agr, vai, ser, tudo, base, profundo, ódio, nu...  \n",
       "3    [@vinimonteuro, @azulgreatcat, minecraft, come...  \n",
       "4    [vou, fazer, casinha, minecraft, alguem, xbox,...  \n",
       "..                                                 ...  \n",
       "445  [sonysta, gosta, vendinhas, saiba, jogo, conso...  \n",
       "446             [odio, insônia, hj…, culpa, minecraft]  \n",
       "447  [@edit_by_fresh, bom, dia, p, hackeado, minecr...  \n",
       "448  [“só, disse, olhar, twitter, dnv”, disse, feli...  \n",
       "449  [9/6, 0403, pedrinho, falar, pica, mano, to, v...  \n",
       "\n",
       "[450 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Stemming: retirar sufixos para se aproximar da raíz da palavra\n",
    "\n",
    "# Inicializando objeto de stemming do nltk\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "lista = []\n",
    "for el in train['Filtrado']:\n",
    "    liste = []\n",
    "    for x in el:\n",
    "        # aplicando o stemming\n",
    "        novo = stemmer.stem(x)\n",
    "        liste.append(novo)\n",
    "    lista.append(liste)\n",
    "train['Stemming'] = lista\n",
    "\n",
    "lista = []\n",
    "for el in test['Filtrado']:\n",
    "    liste = []\n",
    "    for x in el:\n",
    "        # aplicando o stemming\n",
    "        novo = stemmer.stem(x)\n",
    "        liste.append(novo)\n",
    "    lista.append(liste)\n",
    "test['Stemming'] = lista\n",
    "\n",
    "train['Stemming']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                            [part, jog, ❤️, #minecraft]\n",
       "1      [@guilovespink, ah, sim, projet, modpack, tbm,...\n",
       "2      [agr, vai, ser, tud, bas, profund, ódi, nunc, ...\n",
       "3      [@vinimonteur, @azulgreatcat, minecraft, com, ...\n",
       "4      [vou, faz, cas, minecraft, algu, xbox, minecraft]\n",
       "                             ...                        \n",
       "445    [sonyst, gost, vend, saib, jog, consol, vend, ...\n",
       "446                   [odi, insôn, hj…, culp, minecraft]\n",
       "447    [@edit_by_fresh, bom, dia, p, hacke, minecraft...\n",
       "448    [“só, diss, olh, twitt, dnv”, diss, felip, fel...\n",
       "449    [9/6, 0403, pedr, fal, pic, man, to, vend, min...\n",
       "Name: Stemming, Length: 450, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#Agora, com os dados filtrados, iremos de fato ensinar o classificador\r\n",
    "\r\n",
    "#Primeiro precisamos das probabilidades a priori\r\n",
    "contagem_priori = train.loc[:, 'Classificação'].value_counts()\r\n",
    "P_priori = [contagem_priori[0]/len(train), contagem_priori[1]/len(train), contagem_priori[2]/len(train), contagem_priori[3]/len(train)]\r\n",
    "\r\n",
    "#Agora um dicionario com as probabilidade de cada palavra para cada categoria\r\n",
    "dicionario = {0: {}, 1: {}, 2: {}, 3: {}}\r\n",
    "numero_palavras = [0, 0, 0, 0]\r\n",
    "lista_palavras = []\r\n",
    "for tweet_index in range(len(train['Stemming'])):\r\n",
    "    for categoria in range(4):\r\n",
    "        if train['Classificação'][tweet_index] == categoria:\r\n",
    "            numero_palavras[categoria] += len(train['Stemming'][tweet_index])\r\n",
    "            for palavra in train['Stemming'][tweet_index]:\r\n",
    "                lista_palavras.append(palavra)\r\n",
    "numero_palavras_possiveis = len(set(lista_palavras))                \r\n",
    "for tweet_index in range(len(train['Stemming'])):\r\n",
    "    for word in train['Stemming'][tweet_index]:\r\n",
    "        if word not in dicionario[train['Classificação'][tweet_index]]:\r\n",
    "            dicionario[train['Classificação'][tweet_index]][word] = 1/(numero_palavras[train['Classificação'][tweet_index]] + numero_palavras_possiveis)\r\n",
    "        dicionario[train['Classificação'][tweet_index]][word] += 1/(numero_palavras[train['Classificação'][tweet_index]] + numero_palavras_possiveis)\r\n",
    "\r\n",
    "#Função que, dado uma frase, retorna a classificação com maior probabilidade e a média ponderada (score), aplicando a suavização de Laplace no processo\r\n",
    "def Classificador(frase):\r\n",
    "    P_frase = [1, 1, 1, 1]\r\n",
    "    for categoria in range(len(P_frase)):\r\n",
    "        P_frase[categoria] *= P_priori[categoria]\r\n",
    "        for palavra in frase.split():\r\n",
    "            if palavra in dicionario[categoria]:\r\n",
    "                P_frase[categoria] *= dicionario[categoria][palavra]\r\n",
    "            else:\r\n",
    "                P_frase[categoria] *= 1/(numero_palavras[categoria] + numero_palavras_possiveis)\r\n",
    "    melhor_escolha = P_frase.index(max(P_frase))\r\n",
    "    score_escolha = (P_frase[1] + (P_frase[2]*2) + (P_frase[3]*3))/sum(P_frase)\r\n",
    "    return [melhor_escolha, score_escolha]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Variáveis que irão armazenar % de acertos para melhores escolhas, o erro para melhores escolhas\r\n",
    "# e erros para scores\r\n",
    "acurácia = 0\r\n",
    "erro_melhor_escolha = 0\r\n",
    "erro_score = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#Classificar todos os tweets da planilha de testes e colher os resultados\r\n",
    "for tweet_index in range(len(test['Stemming'])):\r\n",
    "    classificação = Classificador(' '.join(test['Stemming'][tweet_index]))\r\n",
    "    if classificação[0] == test['Classificação'][tweet_index]:\r\n",
    "        acurácia += 1\r\n",
    "    erro_melhor_escolha += abs(classificação[0] - test['Classificação'][tweet_index])\r\n",
    "    erro_score += abs(classificação[1] - test['Classificação'][tweet_index])\r\n",
    "acurácia *= 100/len(test['Stemming'])\r\n",
    "erro_melhor_escolha *= (100/3)/len(test['Stemming'])\r\n",
    "erro_score *= (100/3)/len(test['Stemming'])\r\n",
    "\r\n",
    "print(\"Acurácia: \" + str(acurácia) + \"%\")\r\n",
    "print(\"Erro médio considerando a predição do classificador: \" + str(erro_melhor_escolha) + \"%\")\r\n",
    "print(\"Erro médio considerando a ponderação das probabilidades (score): \" + str(erro_score) + \"%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia: 51.59785646887073%\n",
      "Erro médio considerando a predição do classificador: 32.24613814262909%\n",
      "Erro médio considerando a ponderação das probabilidades (score): 30.130673990679316%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "Observando a aplicação do classificador Naive-Bayes para a classificação de relevância dos tweets, é importante ressaltar alguns pontos. Tendo em vista que a divisão entre os integrantes do grupo para a classificação prévia dos tweets não foi feita de forma uniforme, sendo que algumas pessoas apenas participaram do treino e outras do teste. Com isso, era esperado que houvesse um viés diferente na classificação pelo algorítmo, o que interferiu diretamente na acurácia e erros médios. Mesmo assim, os resultados foram satisfatórios, principalmente ao treinar amostras aleatórias, o que aumentou consideravelmente a precisão na maioria dos casos. Com relação ao histograma, é possível observar que ele possui um comportamento quase que simétrico. Com relação aos erros ponderados calculados, é razoavel concluir que considerando as probabilidades de cada classificação, foi possível obter um método mais eficiente (o nosso método fez as probabilidades de 0 a 3 de forma discreta) em oposição o metodo tradicional do modelo (o qual escolhe a maior probabilidade da classificação).Comparando o erro contínuo com o discreto, o discreto é menor, o que revela a eficiência do metodo. Outra coisa importante a se ressaltar foi que o nosso modelo não contém valores \"falso-positivo\" e \"falso-negativo\" já que a sua classificação de relevância entre 0 e 3 não contém esses valores, o que gerou somente uma acurácia e os erros médios envolvendo os modelos de classificação.\r\n",
    "\r\n",
    "Respondendo à pergunta da professora, não é possível usar o mesmo classificador para mais amostras de treinamento, uma vez que o classificador depende das frequências absolutas das palavras de cada classificação, o que pode variar dependendo do grupo amostral de treinamento. Uma melhoria real a ser implementada seria a filtragem de acentos, o que não foi feita, pois interferiria na exibição dos emojis. Um outro cenário o qual é interessante aplicar esse modelo de classificador é na filtragem de e-mails para o SPAM, também podendo ser utilizado como sugestão de ítens para usuários em diversos aplicativos. como na recomendação de filmes na Netflix, por exemplo.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Construindo uma dataframe com todos os tweets\r\n",
    "\r\n",
    "train2 = pd.read_excel(filename)\r\n",
    "train2 = train2.loc[:,['Treinamento','Rafa','Classificação']]\r\n",
    "train2.columns = ['Tweet','Integrante','Classificação']\r\n",
    "\r\n",
    "test2 = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test2 = test2.loc[:,['Teste','Unnamed: 14','Classificador']]\r\n",
    "test2.columns = ['Tweet','Integrante','Classificação']\r\n",
    "\r\n",
    "sheets = [train2,test2]\r\n",
    "\r\n",
    "completo = pd.concat(sheets)\r\n",
    "\r\n",
    "completo\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Integrante</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partiu jogar ❤️\\n\\n#minecraft</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@guilovespink ah sim, eu tenho meu projetinho ...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agr vai ser tudo na base do mais profundo ódio...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vinimonteuro @azulgreatcat minecraft comes al...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vou fazer casinha no minecraft\\n\\nalguem tem x...</td>\n",
       "      <td>Rafa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>saudades da vic falando que eu to igual minecr...</td>\n",
       "      <td>Catapano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>@lilithphile imagina os kookmin no minecraft d...</td>\n",
       "      <td>Catapano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>@bolovodeovo @joaovitokkkkk como se tu nunca t...</td>\n",
       "      <td>Catapano</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tô tentando zerar minecraft (pela primeira vez...</td>\n",
       "      <td>Catapano</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>as vezes eu paro e penso \"mano, fiz 11 horas d...</td>\n",
       "      <td>Catapano</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>687 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet Integrante  \\\n",
       "0                        partiu jogar ❤️\\n\\n#minecraft       Rafa   \n",
       "1    @guilovespink ah sim, eu tenho meu projetinho ...       Rafa   \n",
       "2    agr vai ser tudo na base do mais profundo ódio...       Rafa   \n",
       "3    @vinimonteuro @azulgreatcat minecraft comes al...       Rafa   \n",
       "4    vou fazer casinha no minecraft\\n\\nalguem tem x...       Rafa   \n",
       "..                                                 ...        ...   \n",
       "232  saudades da vic falando que eu to igual minecr...   Catapano   \n",
       "233  @lilithphile imagina os kookmin no minecraft d...   Catapano   \n",
       "234  @bolovodeovo @joaovitokkkkk como se tu nunca t...   Catapano   \n",
       "235  tô tentando zerar minecraft (pela primeira vez...   Catapano   \n",
       "236  as vezes eu paro e penso \"mano, fiz 11 horas d...   Catapano   \n",
       "\n",
       "     Classificação  \n",
       "0                2  \n",
       "1                3  \n",
       "2                0  \n",
       "3                0  \n",
       "4                2  \n",
       "..             ...  \n",
       "232              1  \n",
       "233              1  \n",
       "234              0  \n",
       "235              3  \n",
       "236              2  \n",
       "\n",
       "[687 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Formando diferentes amostras de teste e treinamento e comparando a eficácia do classificador:\r\n",
    "\r\n",
    "acertos = []\r\n",
    "\r\n",
    "for i in range(1,101):\r\n",
    "    # Formando amostras:\r\n",
    "    train = completo.sample(frac=0.6,random_state=i)\r\n",
    "    train = train.reset_index(drop=True)\r\n",
    "    test = completo.drop(train.index).sample(frac=1.0)\r\n",
    "    test = test.reset_index(drop=True)\r\n",
    "    # Filtrando:\r\n",
    "    train[\"Tweet\"].str.lower()\r\n",
    "    test[\"Tweet\"].str.lower()\r\n",
    "    lista = list()\r\n",
    "    for el in train[\"Tweet\"]:\r\n",
    "        # Tira espaços extras\r\n",
    "        limpando = \" \".join(el.split())\r\n",
    "        words = limpando.split()\r\n",
    "        lista.append(words)\r\n",
    "    train[\"Palavras\"] = lista\r\n",
    "\r\n",
    "    lista = list()\r\n",
    "    for el in test[\"Tweet\"]:\r\n",
    "        # Tira espaços extras\r\n",
    "        limpando = \" \".join(el.split())\r\n",
    "        words = limpando.split()\r\n",
    "        lista.append(words)\r\n",
    "    test[\"Palavras\"] = lista\r\n",
    "\r\n",
    "    lista = list()\r\n",
    "    for el in train['Palavras']:\r\n",
    "        liste = []\r\n",
    "        for x in el:\r\n",
    "            if any(char in charstop for char in x):\r\n",
    "                for stp in charstop:\r\n",
    "                    x = x.replace(stp,\"\")\r\n",
    "            if x != \"\" and (x not in palavrastop and x not in stopwords.words('portuguese')):\r\n",
    "                liste.append(x)\r\n",
    "        lista.append(liste)\r\n",
    "    train['Filtrado'] = lista\r\n",
    "\r\n",
    "    lista = list()\r\n",
    "    for el in test['Palavras']:\r\n",
    "        liste = []\r\n",
    "        for x in el:\r\n",
    "            if any(char in charstop for char in x):\r\n",
    "                for stp in charstop:\r\n",
    "                    x = x.replace(stp,\"\")\r\n",
    "            if x != \"\" and (x not in palavrastop and x not in stopwords.words('portuguese')):\r\n",
    "                liste.append(x)\r\n",
    "        lista.append(liste)\r\n",
    "    test['Filtrado'] = lista\r\n",
    "\r\n",
    "    lista = []\r\n",
    "    for el in train['Filtrado']:\r\n",
    "        liste = []\r\n",
    "        for x in el:\r\n",
    "            # aplicando o stemming\r\n",
    "            novo = stemmer.stem(x)\r\n",
    "            liste.append(novo)\r\n",
    "        lista.append(liste)\r\n",
    "    train['Stemming'] = lista\r\n",
    "\r\n",
    "    lista = []\r\n",
    "    for el in test['Filtrado']:\r\n",
    "        liste = []\r\n",
    "        for x in el:\r\n",
    "            # aplicando o stemming\r\n",
    "            novo = stemmer.stem(x)\r\n",
    "            liste.append(novo)\r\n",
    "        lista.append(liste)\r\n",
    "    test['Stemming'] = lista\r\n",
    "\r\n",
    "    # Montando o classificador:\r\n",
    "    contagem_priori = train.loc[:, 'Classificação'].value_counts()\r\n",
    "    P_priori = [contagem_priori[0]/len(train), contagem_priori[1]/len(train), contagem_priori[2]/len(train), contagem_priori[3]/len(train)]\r\n",
    "\r\n",
    "    dicionario = {0: {}, 1: {}, 2: {}, 3: {}}\r\n",
    "    numero_palavras = [0, 0, 0, 0]\r\n",
    "    lista_palavras = []\r\n",
    "    for tweet_index in range(len(train['Stemming'])):\r\n",
    "        for categoria in range(4):\r\n",
    "            if train['Classificação'][tweet_index] == categoria:\r\n",
    "                numero_palavras[categoria] += len(train['Stemming'][tweet_index])\r\n",
    "                for palavra in train['Stemming'][tweet_index]:\r\n",
    "                    lista_palavras.append(palavra)\r\n",
    "    numero_palavras_possiveis = len(set(lista_palavras))                \r\n",
    "    for tweet_index in range(len(train['Stemming'])):\r\n",
    "        for word in train['Stemming'][tweet_index]:\r\n",
    "            if word not in dicionario[train['Classificação'][tweet_index]]:\r\n",
    "                dicionario[train['Classificação'][tweet_index]][word] = 1/(numero_palavras[train['Classificação'][tweet_index]] + numero_palavras_possiveis)\r\n",
    "            dicionario[train['Classificação'][tweet_index]][word] += 1/(numero_palavras[train['Classificação'][tweet_index]] + numero_palavras_possiveis)\r\n",
    "    # Classificando:\r\n",
    "    acuracia = 0\r\n",
    "    for tweet_index in range(len(test['Stemming'])):\r\n",
    "        classificação = Classificador(' '.join(test['Stemming'][tweet_index]))\r\n",
    "        if classificação[0] == test['Classificação'][tweet_index]:\r\n",
    "            acuracia += 1\r\n",
    "    acuracia *= 100/len(test['Stemming'])\r\n",
    "    acertos.append(acuracia)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Plotando um histograma com a porcentagem de acertos:\r\n",
    "\r\n",
    "faixa = np.arange(0,101,5)\r\n",
    "\r\n",
    "plt.hist(acertos,bins=faixa,density=True,edgecolor='white')\r\n",
    "plt.xlabel('Porcentagem de acerto')\r\n",
    "plt.ylabel('Densidade')\r\n",
    "plt.title('Histograma das porcentagens de acerto')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "✔️ IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "\n",
    "✔️ CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "\n",
    "✔️ CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c51205f17265714c04c5cef09a6617a136cbe43b6fbb555d14e67c19a595607f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}